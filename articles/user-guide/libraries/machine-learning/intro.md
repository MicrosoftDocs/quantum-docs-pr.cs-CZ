---
title: Knihovna pro kvantové strojové učení
author: alexeib2
ms.author: alexei.bocharov@microsoft.com
ms.date: 11/22/2019
ms.topic: article
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: 65b0aa6a7f385765933d4d89ce34901f77cf76ec
ms.sourcegitcommit: 75c4edc7c410cc63dc8352e2a5bef44b433ed188
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 08/25/2020
ms.locfileid: "88863106"
---
# <a name="introduction-to-quantum-machine-learning"></a><span data-ttu-id="d4b36-102">Seznámení s Machine Learningmi</span><span class="sxs-lookup"><span data-stu-id="d4b36-102">Introduction to Quantum Machine Learning</span></span>

## <a name="framework-and-goals"></a><span data-ttu-id="d4b36-103">Architektura a cíle</span><span class="sxs-lookup"><span data-stu-id="d4b36-103">Framework and goals</span></span>

<span data-ttu-id="d4b36-104">Zátěžové kódování a zpracování informací je neefektivní alternativou pro třídění klasických procesorů strojového učení.</span><span class="sxs-lookup"><span data-stu-id="d4b36-104">Quantum encoding and processing of information is a powerful alternative to classical machine learning Quantum classifiers.</span></span> <span data-ttu-id="d4b36-105">Konkrétně umožňuje kódovat data v registrech v obdobích, která jsou stručně relativní vzhledem k počtu funkcí a systematicky se využívaly entanglement jako výpočetní prostředky a využívají měření za běhu pro odvození třídy.</span><span class="sxs-lookup"><span data-stu-id="d4b36-105">In particular, it allows us to encode data in quantum registers that are concise relative to the number of features, systematically employing quantum entanglement as computational resource and employing quantum measurement for class inference.</span></span>
<span data-ttu-id="d4b36-106">Klasifikátor pro nedodržení okruhu je poměrně jednoduché řešení pro všechna množství, které kombinuje kódování dat s rychle entanglingm nebo disentanglingm okruhem, za nímž následuje měření pro odvození popisků tříd v ukázkách dat.</span><span class="sxs-lookup"><span data-stu-id="d4b36-106">Circuit centric quantum classifier is a relatively simple quantum solution that combines data encoding with a rapidly entangling/disentangling quantum circuit followed by measurement to infer class labels of data samples.</span></span>
<span data-ttu-id="d4b36-107">Cílem je zajistit v případě extrémně velkých prostorů funkcí klasický popis a ukládání okruhů předmětu a také hybridních a klasických školení parametrů okruhu.</span><span class="sxs-lookup"><span data-stu-id="d4b36-107">The goal is to ensure classical characterization and storage of subject circuits, as well as hybrid quantum/classical training of the circuit parameters even for extremely large feature spaces.</span></span>

## <a name="classifier-architecture"></a><span data-ttu-id="d4b36-108">Architektura klasifikátoru</span><span class="sxs-lookup"><span data-stu-id="d4b36-108">Classifier architecture</span></span>

<span data-ttu-id="d4b36-109">Klasifikace je úloha strojového učení pod dohledem, kde cílem je odvozovat štítky tříd $ \{ y_1, y_2, \ldots, y_d \} $ z určitých ukázek dat.</span><span class="sxs-lookup"><span data-stu-id="d4b36-109">Classification is a supervised machine learning task, where the goal is to infer class labels $\{y_1,y_2,\ldots,y_d\}$ of certain data samples.</span></span> <span data-ttu-id="d4b36-110">"Školicí data sada" je kolekce vzorků $ \mathcal{D} = \{ (x, y)} $ se známými předem přiřazenými popisky.</span><span class="sxs-lookup"><span data-stu-id="d4b36-110">The "training data set" is a collection of samples $\mathcal{D}=\{(x,y)}$ with known pre-assigned labels.</span></span> <span data-ttu-id="d4b36-111">Tady $x $ je ukázka dat a $y $ je známý popisek s názvem "školení".</span><span class="sxs-lookup"><span data-stu-id="d4b36-111">Here $x$ is a data sample and $y$ is its known label called "training label".</span></span>
<span data-ttu-id="d4b36-112">Podobně jako u tradičních metod se klasifikace nestandardních hodnot skládá ze tří kroků:</span><span class="sxs-lookup"><span data-stu-id="d4b36-112">Somewhat similar to traditional methods, quantum classification consists of three steps:</span></span>
- <span data-ttu-id="d4b36-113">kódování dat</span><span class="sxs-lookup"><span data-stu-id="d4b36-113">data encoding</span></span>
- <span data-ttu-id="d4b36-114">Příprava stavu třídění</span><span class="sxs-lookup"><span data-stu-id="d4b36-114">preparation of a classifier state</span></span>
- <span data-ttu-id="d4b36-115">měření z důvodu pravděpodobnostní povahy měření se tyto tři kroky musí opakovat několikrát.</span><span class="sxs-lookup"><span data-stu-id="d4b36-115">measurement Due to the probabilistic nature of the measurement, these three steps must be repeated multiple times.</span></span> <span data-ttu-id="d4b36-116">Jak kódování, tak i výpočet stavu třídění se provádí prostřednictvím *okruhů*v počtu.</span><span class="sxs-lookup"><span data-stu-id="d4b36-116">Both the encoding and the computing of the classifier state are done by means of *quantum circuits*.</span></span> <span data-ttu-id="d4b36-117">I když je okruh kódování obvykle řízený daty a bez parametrů, okruh třídění obsahuje dostatečnou sadu podrobnějších parametrů.</span><span class="sxs-lookup"><span data-stu-id="d4b36-117">While the encoding circuit is usually data-driven and parameter-free, the classifier circuit contains a sufficient set of learnable parameters.</span></span> 

<span data-ttu-id="d4b36-118">V navrhovaném řešení se okruh třídění skládá z qubit otočení a dvou qubit řízených otočení.</span><span class="sxs-lookup"><span data-stu-id="d4b36-118">In the proposed solution the classifier circuit is composed of single-qubit rotations and two-qubit controlled rotations.</span></span> <span data-ttu-id="d4b36-119">Zde popsané parametry jsou úhly otočení.</span><span class="sxs-lookup"><span data-stu-id="d4b36-119">The learnable parameters here are the rotation angles.</span></span> <span data-ttu-id="d4b36-120">Pro výpočet nenáročných hodnot se ví, že se u zařízení pro rotaci a řízenému otočení označují *univerzální* , což znamená, že jakákoli Jednotková matice je možné rozložit do dostatečně dlouhého okruhu skládajícího se z těchto bran</span><span class="sxs-lookup"><span data-stu-id="d4b36-120">The rotation and controlled rotation gates are known to be *universal* for quantum computation, which means that any unitary weight matrix can be decomposed into a long enough circuit consisting of such gates.</span></span>

<span data-ttu-id="d4b36-121">V navržené verzi se podporuje jenom jeden okruh následovaný jedním odhadem frekvence.</span><span class="sxs-lookup"><span data-stu-id="d4b36-121">In the proposed version, only one circuit followed by a single frequency estimation is supported.</span></span>
<span data-ttu-id="d4b36-122">Proto řešení je obdobou nenáročného na počítač, který podporuje Vektorový procesor s nízkou úrovní polynomu.</span><span class="sxs-lookup"><span data-stu-id="d4b36-122">Thus, the solution is a quantum analog of a support vector machine with a low-degree polynomial kernel.</span></span>

![Multilayer Perceptron vs. třídění orientované na okruhy](~/media/DLvsQCC.png)

<span data-ttu-id="d4b36-124">Jednoduchý návrh klasifikátoru pro období se dá porovnat s tradičním řešením SVM (support Vector Machine).</span><span class="sxs-lookup"><span data-stu-id="d4b36-124">A simple quantum classifier design can be compared to a traditional support vector machine (SVM) solution.</span></span> <span data-ttu-id="d4b36-125">Odvození pro ukázku dat $x $ v případě SVM se provádí pomocí optimálního formuláře jádra $ \sum \ alpha_j k (x_j, x) $, kde $k $ je určitá funkce jádra.</span><span class="sxs-lookup"><span data-stu-id="d4b36-125">The inference for a data sample $x$ in case of SVM is done using an optimal kernel form $\sum \alpha_j  k(x_j,x)$ where $k$ is a certain kernel function.</span></span>

<span data-ttu-id="d4b36-126">Naproti tomu klasifikátorní využití používá prediktivní $p (y │ x, U (\theta)) = 〈 U (\theta) x | M | U (\theta) × 〉 $, která je v duchu podobná, ale technicky poměrně odlišná.</span><span class="sxs-lookup"><span data-stu-id="d4b36-126">By contrast, a quantum classifier uses the predictor $p(y│x,U(\theta))=〈U(\theta)x|M|U(\theta)x〉$, which is similar in spirit but technically quite different.</span></span> <span data-ttu-id="d4b36-127">Proto když se používá přímočarý kódovací kódování, $p (y │ x, U (\theta)) $ je kvadratická forma ve amplitudách $x $, ale součinitele tohoto formuláře se již nenaučí. místo toho jsou agregovány z prvků matice $U okruhu (\theta) $, což obvykle má výrazně méně možností s možností učení $ \theta $, než je dimenze vektoru $x $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-127">Thus, when a straightforward amplitude encoding is used,  $p(y│x,U(\theta))$ is a quadratic form in the amplitudes of $x$, but the coefficients of this form are no longer learned independently; they are instead aggregated from the matrix elements of the circuit $U(\theta)$, which typically has significantly fewer learnable parameters $\theta$ than the dimension of the vector $x$.</span></span> <span data-ttu-id="d4b36-128">Stupeň polynomu $p (y │ x, U (\theta)) $ v původních funkcích se dá zvýšit na $2 ^ l $ pomocí kódování produktového pole v $l $ kopiích $x $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-128">The polynomial degree of $p(y│x,U(\theta))$ in the original features can be increased to $2^l$ by using a quantum product encoding on $l$ copies of $x$.</span></span>

<span data-ttu-id="d4b36-129">Naše architektura zkoumá relativně omezené okruhy, které proto musí být *rychle Entangling* , aby bylo možné zachytit všechny korelace mezi funkcemi dat ve všech oblastech.</span><span class="sxs-lookup"><span data-stu-id="d4b36-129">Our architecture explores relatively shallow circuits, which therefore must be *rapidly entangling* in order to capture all the correlations between the data features at all ranges.</span></span> <span data-ttu-id="d4b36-130">Příkladem nejužitečnější komponenty pro rychlé Entangling okruhy vidíte na obrázku níže.</span><span class="sxs-lookup"><span data-stu-id="d4b36-130">An example of the most useful rapidly entangling circuit component is shown on figure below.</span></span> <span data-ttu-id="d4b36-131">I když okruh s touto geometrií sestává jenom z $3 n + 1 $ bran, matice s jednotkou váhy, kterou COMPUTE počítá, zajišťuje významné vzájemné rozhovory mezi funkcemi $2 ^ n $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-131">Even though a circuit with this geometry consists of only $3 n+1$ gates, the unitary weight matrix that it computes ensures significant cross-talk between $2^n$ features.</span></span>

![Rychle entanglingský okruh na 5 qubits (se dvěma cykly cyklických vrstev).](~/media/5-qubit-qccc.png)

<span data-ttu-id="d4b36-133">Okruh v předchozím příkladu se skládá z 6 qubit bran $ (G_1, \ldots, G_5; G_ {16} ) $ a 10 2-qubits brány $ (G_6, \ldots, G_ {15} ) $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-133">The circuit in the above example consists of 6 single-qubit gates $(G_1,\ldots,G_5; G_{16})$ and 10 two-qubits gates $(G_6,\ldots,G_{15})$.</span></span> <span data-ttu-id="d4b36-134">Za předpokladu, že každá z bran je definovaná s jedním parametrem s příznakem, máme 16 zjistitelné parametry, ale rozměr 5-qubit Hilbert místa je 32.</span><span class="sxs-lookup"><span data-stu-id="d4b36-134">Assuming that each of the gates is defined with one learnable parameter we have 16 learnable parameters, while the dimension of the 5-qubit Hilbert space is 32.</span></span> <span data-ttu-id="d4b36-135">Tato geometrie okruhů se dá snadno zobecnit na jakýkoli $n $-qubit registr, pokud je $n $ lichá, poskytují okruhy s $3 n + 1 $ parametry pro $2 ^ n $ dimenzionální prostor funkcí.</span><span class="sxs-lookup"><span data-stu-id="d4b36-135">Such circuit geometry can be easily generalized to any $n$-qubit register, when $n$ is odd, yielding circuits with $3 n+1$ parameters for $2^n$-dimensional feature space.</span></span>

## <a name="classifier-training-as-a-supervised-learning-task"></a><span data-ttu-id="d4b36-136">Školení klasifikátoru jako úkol pod dohledem</span><span class="sxs-lookup"><span data-stu-id="d4b36-136">Classifier training as a supervised learning task</span></span>

<span data-ttu-id="d4b36-137">Školení modelu třídění zahrnuje hledání optimálních hodnot jeho provozních parametrů, aby se maximalizovala Průměrná pravděpodobnost odvození správných školicích popisků v rámci školicích ukázek.</span><span class="sxs-lookup"><span data-stu-id="d4b36-137">Training of a classifier model involves finding optimal values of its operational parameters, such that they maximize the average likelihood of inferring the correct training labels across the training samples.</span></span>
<span data-ttu-id="d4b36-138">Tady se týkají pouze dodržovali se dvěma klasifikací na úrovni, tj. případ $d = $2 a pouze dvě třídy s popisky $y _1, y_2 $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-138">Here, we concern ourselves with two level classification only, i.e. the case of $d=2$ and only two classes with the labels $y_1,y_2$.</span></span>

> [!NOTE]
> <span data-ttu-id="d4b36-139">Princip generalizace našich metod pro libovolný počet tříd je nahradit qubits pomocí qudits, tj. jednotky v hodnotě $d $ základních stavů a obousměrnou měření pomocí $d $-Way měření.</span><span class="sxs-lookup"><span data-stu-id="d4b36-139">A principled way of generalizing our methods to arbitrary number of classes is to replace qubits with qudits, i.e. quantum units with $d$ basis states, and the two-way measurement with $d$-way measurement.</span></span>

### <a name="likelihood-as-the-training-goal"></a><span data-ttu-id="d4b36-140">Pravděpodobnost jako cíl školení</span><span class="sxs-lookup"><span data-stu-id="d4b36-140">Likelihood as the training goal</span></span>

<span data-ttu-id="d4b36-141">Vzhledem k poměrnému okruhu $U (\theta) $, kde $ \theta $ je vektor parametrů a označuje konečné měření pomocí $M $, je průměrná pravděpodobnost správného odvození popisku $ $ \begin{align} \mathcal{L} (\theta) = \frac {1} {| \mathcal{D} |} \left (\ sum_ {(x, y_1) \In\mathcal{D}} P (M = y_1 | U (\theta) x) + \ sum_ {(x, y_2) \in\mathcal{D}} P (M = y_2 | U (\theta) x) \right) \end{align} $ $ WHERE $P (M = y | z) $ je pravděpodobnost měření $y $ v stavovém poli $z $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-141">Given a learnable quantum circuit $U(\theta)$, where $\theta$ is a vector of parameters, and denoting the final measurement by $M$, the average likelihood of the correct label inference is $$ \begin{align} \mathcal{L}(\theta)=\frac{1}{|\mathcal{D}|} \left( \sum_{(x,y_1)\in\mathcal{D}} P(M=y_1|U(\theta) x) + \sum_{(x,y_2)\in\mathcal{D}} P(M=y_2|U(\theta) x)\right) \end{align} $$ where $P(M=y|z)$ is the probability of measuring $y$ in quantum state $z$.</span></span>
<span data-ttu-id="d4b36-142">V tomto případě stačí pochopit, že pravděpodobnost funkce $ \mathcal{L} (\theta) $ je hladká v $ \theta $ a její deriváty v jakékoli $ \ theta_j $ se dají vypočítat v podstatě stejným protokolem, který se používá pro výpočet pravděpodobnosti samotné funkce.</span><span class="sxs-lookup"><span data-stu-id="d4b36-142">Here, it suffices to understand that the likelihood function $\mathcal{L}(\theta)$ is smooth in $\theta$ and its derivative in any $\theta_j$ can be computed by essentially the same quantum protocol as used for computing the likelihood function itself.</span></span> <span data-ttu-id="d4b36-143">To umožňuje optimalizovat $ \mathcal{L} (\theta) $ podle barevného sklonu proklesání.</span><span class="sxs-lookup"><span data-stu-id="d4b36-143">This allows for optimizing the $\mathcal{L}(\theta)$ by gradient descent.</span></span>

### <a name="classifier-bias-and-training-score"></a><span data-ttu-id="d4b36-144">Posunutí klasifikátoru a skóre školení</span><span class="sxs-lookup"><span data-stu-id="d4b36-144">Classifier bias and training score</span></span>

<span data-ttu-id="d4b36-145">U některých mezilehlých (nebo konečných) hodnot parametrů v $ \theta $ potřebujeme identifikovat jednu skutečnou hodnotu, $b $ ví jako *posun klasifikátoru* k odvození.</span><span class="sxs-lookup"><span data-stu-id="d4b36-145">Given some intermediate (or final) values of the parameters in $\theta$, we need to identify a single real value $b$ know as *classifier bias* to do the inference.</span></span> <span data-ttu-id="d4b36-146">Pravidlo odvození popisku funguje takto:</span><span class="sxs-lookup"><span data-stu-id="d4b36-146">The label inference rule works as follows:</span></span> 
- <span data-ttu-id="d4b36-147">Vzorový $x $ je přiřazený popisek $y _2 $ if a jenom v případě, že $P (M = y_2 | U (\theta) x) + b > $0,5 (RULE1) (v opačném případě se mu přiřadí jmenovka $y _1 $)</span><span class="sxs-lookup"><span data-stu-id="d4b36-147">A sample $x$ is assigned label $y_2$ if and only if $P(M=y_2|U(\theta) x) + b > 0.5$  (RULE1) (otherwise it is assigned label $y_1$)</span></span>

<span data-ttu-id="d4b36-148">Jasně $b $ musí být v intervalu $ (-0.5, + 0,5) $, aby byly smysluplné.</span><span class="sxs-lookup"><span data-stu-id="d4b36-148">Clearly $b$ must be in the interval $(-0.5,+0.5)$ to be meaningful.</span></span>

<span data-ttu-id="d4b36-149">Školicí případ $ (x, y) \in \mathcal{D} $ se považuje za chybnou *klasifikaci* daného posunutí $b $, pokud je popisek odvozený pro $x $ jako na RULE1 v podstatě jiný než $y $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-149">A training case $(x,y) \in \mathcal{D}$ is considered a *misclassification* given the bias $b$ if the label inferred for $x$ as per RULE1 is actually different from $y$.</span></span> <span data-ttu-id="d4b36-150">Celkový počet chybných klasifikací je *školicím skórem* daného třídění, které odpovídá posunu $b $.</span><span class="sxs-lookup"><span data-stu-id="d4b36-150">The overall number of misclassifications is the *training score* of the classifier given the bias $b$.</span></span> <span data-ttu-id="d4b36-151">*Optimální* posun klasifikátoru $b $ minimalizuje skóre školení.</span><span class="sxs-lookup"><span data-stu-id="d4b36-151">The *optimal* classifier bias $b$ minimizes the training score.</span></span> <span data-ttu-id="d4b36-152">Je snadné zjistit, že s ohledem na odhad předpočítaných pravděpodobností $ \{ P (M = y_2 | U (\theta) x) | (x, \*) \in\mathcal{D} \} $, optimální posun klasifikátoru lze najít pomocí binárního vyhledávání v intervalu $ (-0,5, + 0,5) $ tím, že se provede maximálně $ \ Log_2 (| \mathcal{D} |). $ kroky.</span><span class="sxs-lookup"><span data-stu-id="d4b36-152">It is easy to see that, given the precomputed probability estimates $\{ P(M=y_2|U(\theta) x) | (x,\*)\in\mathcal{D} \}$, the optimal classifier bias can be found by binary search in interval $(-0.5,+0.5)$ by making at most $\log_2(|\mathcal{D}|)$ steps.</span></span>

### <a name="reference"></a><span data-ttu-id="d4b36-153">Referenční informace</span><span class="sxs-lookup"><span data-stu-id="d4b36-153">Reference</span></span>

<span data-ttu-id="d4b36-154">Tyto informace by měly být dostatečné pro zahájení přehrávání s kódem.</span><span class="sxs-lookup"><span data-stu-id="d4b36-154">This information should be enough to start playing with the code.</span></span> <span data-ttu-id="d4b36-155">Pokud ale chcete získat další informace o tomto modelu, přečtěte si prosím původní návrh: [ *"klasifikátory zaměřené na okruhy", Marie Schuld, Alex Bocharov, Krysta Svore a Nathan* Wiebe](https://arxiv.org/abs/1804.00633)</span><span class="sxs-lookup"><span data-stu-id="d4b36-155">However, if you want to learn more about this model, please read the original proposal: [*'Circuit-centric quantum classifiers', Maria Schuld, Alex Bocharov, Krysta Svore and Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span></span>

<span data-ttu-id="d4b36-156">Kromě ukázky kódu, který se zobrazí v dalších krocích, můžete také začít zkoumat klasifikaci nepočátečních hodnot v [tomto kurzu](https://github.com/microsoft/QuantumKatas/tree/master/tutorials/QuantumClassification) .</span><span class="sxs-lookup"><span data-stu-id="d4b36-156">In addition to the code sample you will see in the next steps, you can also start exploring quantum classification in [this tutorial](https://github.com/microsoft/QuantumKatas/tree/master/tutorials/QuantumClassification)</span></span> 
